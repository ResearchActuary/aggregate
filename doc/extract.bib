@article{Anderson1988,
 abstract = {In recent years catastrophe reinsurers' use of catastrophe models has been increasing until currently virtually all of the catastrophe reinsurers in the world use a catastrophe model to aid them in their pricing and portfolio management decisions. This paper explicitly models various types of reinstatement provisions, including reinstatements that are limited by the number of occurrences and by the aggregate losses; and reinstatement premiums based on the size of loss and by the time elapsed to the first occurrence. The paper also investigates the effects on the fair premium of a catastrophe treaty when various reinstatement provisions are considered. This is an expansion of the methods developed in papers by Leroy J. Simon and Bjom Sundt, which were written before the widespread use of catastrophe models. The catastrophe model used for this paper is the Insurance / Investment Risk Assessment System (IRAS) produced by Risk Management Solutions, Inc.},
 author = {Anderson, RR and Dong, Wemin},
 file = {:C\:/S/Library/Anderson, Dong/1988_Pricing catastrophe reinsurance with reinstatement provisions using a catastrophe model.pdf:pdf},
 journal = {Casualty Actuarial Society Forum},
 pages = {303--322},
 title = {{Pricing catastrophe reinsurance with reinstatement provisions using a catastrophe model}},
 url = {http://casact.net/education/ratesem/99handouts/anderson.pdf},
 year = {1988}
}

@article{Bear1990,
 author = {Bear, R.A. and Nemlick, K.J.},
 doi = {10.1016/0167-6687(93)91078-9},
 file = {:C\:/S/Library/Bear, Nemlick/1990_Pricing the impact of adjustable features and loss sharing provisions of reinsurance treaties.pdf:pdf},
 issn = {01676687},
 journal = {Proceedings of the Casualty Actuarial Society},
 number = {147},
 pages = {86--87},
 title = {{Pricing the impact of adjustable features and loss sharing provisions of reinsurance treaties}},
 volume = {77},
 year = {1990}
}

@article{Bernegger1997,
 author = {Bernegger, Stefan},
 file = {:C\:/S/Library/Bernegger/1997_The Swiss Re exposure curves and the MBBEFD distribution class.pdf:pdf},
 journal = {ASTIN Bulletin},
 number = {1},
 pages = {99--111},
 title = {{The Swiss Re exposure curves and the MBBEFD distribution class}},
 volume = {27},
 year = {1997}
}

@article{Boonen2017,
 abstract = {Existing risk capital allocation methods, such as the Euler rule, work under the explicit assumption that portfolios are formed as linear combinations of random loss/profit variables, with the firm being able to choose the portfolio weights. This assumption is unrealistic in an insurance context, where arbitrary scaling of risks is generally not possible. Here, we model risks as being partially generated by L{\'{e}}vy processes, capturing the non-linear aggregation of risk. The model leads to non-homogeneous fuzzy games, for which the Euler rule is not applicable. For such games, we seek capital allocations that are in the core, that is, do not provide incentives for splitting portfolios. We show that the Euler rule of an auxiliary linearised fuzzy game (non-uniquely) satisfies the core property and, thus, provides a plausible and easily implemented capital allocation. In contrast, the Aumann–Shapley allocation does not generally belong to the core. For the non-homogeneous fuzzy games studied, Tasche's (1999) criterion of suitability for performance measurement is adapted and it is shown that the proposed allocation method gives appropriate signals for improving the portfolio underwriting profit.},
 author = {Boonen, Tim J. and Tsanakas, Andreas and W{\"{u}}thrich, Mario V.},
 doi = {10.1016/j.insmatheco.2016.11.003},
 file = {:C\:/S/Library/Boonen, Tsanakas, W{\"{u}}thrich/2017_Capital allocation for portfolios with non-linear risk aggregation(2).pdf:pdf},
 issn = {01676687},
 journal = {Insurance: Mathematics and Economics},
 keywords = {Aumann–Shapley value,Capital allocation,Euler rule,Fuzzy core,Risk measures,Tsanakas},
 mendeley-tags = {Tsanakas},
 pages = {95--106},
 title = {{Capital allocation for portfolios with non-linear risk aggregation}},
 volume = {72},
 year = {2017}
}

@article{Clark2014,
 author = {Clark, David R},
 file = {:C\:/S/Library/Clark/2014_Basics of Reinsurance Pricing Actuarial Study Note Basics of Reinsurance Pricing.pdf:pdf},
 journal = {CAS Study Note},
 title = {{Basics of Reinsurance Pricing Actuarial Study Note Basics of Reinsurance Pricing}},
 url = {http://www.casact.org/library/studynotes/Clark_2014.pdf},
 year = {2014}
}

@article{Denuit2019,
 abstract = {Using risk-reducing properties of conditional expectations with respect to convex order, Denuit and Dhaene [Denuit, M. and Dhaene, J. (2012). Insurance: Mathematics and Economics 51, 265-270] proposed the conditional mean risk sharing rule to allocate the total risk among participants to an insurance pool. This paper relates the conditional mean risk sharing rule to the size-biased transform when pooled risks are independent. A representation formula is first derived for the conditional expectation of an individual risk given the aggregate loss. This formula is then exploited to obtain explicit expressions for the contributions to the pool when losses are modeled by compound Poisson sums, compound Negative Binomial sums, and compound Binomial sums, to which Panjer recursion applies. Simple formulas are obtained when claim severities are homogeneous. A couple of applications are considered: first, to a peer-to-peer insurance scheme where participants share the first layer of their respective risks while the higher layer is ceded to a (re)insurer; second, to survivor credits to be shared among surviving participants in tontine schemes.},
 author = {Denuit, Michel},
 doi = {10.1017/asb.2019.24},
 file = {:C\:/S/Library/Denuit/2019_Size-biased transform and conditional mean risk sharing, with application to p2p insurance and tontines.pdf:pdf},
 issn = {17831350},
 journal = {ASTIN Bulletin},
 keywords = {Conditional expectation,Panjer family of distributions,compound distributions,risk measures,risk pooling},
 number = {3},
 pages = {591--617},
 title = {{Size-biased transform and conditional mean risk sharing, with application to p2p insurance and tontines}},
 volume = {49},
 year = {2019}
}

@article{Embrechts2009a,
 abstract = {Numerical evaluation of compound distributions is an important task in insurance mathematics and quantitative risk management. In practice, both recursive methods as well as transform based techniques are widely used. We give a survey of these tools, point out the respective merits and provide some numerical examples. {\textcopyright} 2008 Springer-Verlag.},
 author = {Embrechts, Paul and Frei, Marco},
 doi = {10.1007/s00186-008-0249-2},
 file = {:C\:/S/Library/Embrechts, Frei/2009_Panjer recursion versus FFT for compound distributions.pdf:pdf},
 issn = {14322994},
 journal = {Mathematical Methods of Operations Research},
 keywords = {Compound distributions,Fast Fourier transform,Panjer recursion,Risk management},
 number = {3},
 pages = {497--508},
 title = {{Panjer recursion versus FFT for compound distributions}},
 volume = {69},
 year = {2009}
}

@article{Embrechts2013,
 abstract = {Despite well-known shortcomings as a risk measure, Value-at-Risk (VaR) is still the industry and regulatory standard for the calculation of risk capital in banking and insurance. This paper is concerned with the numerical estimation of the VaR for a portfolio position as a function of different dependence scenarios on the factors of the portfolio. Besides summarizing the most relevant analytical bounds, including a discussion of their sharpness, we introduce a numerical algorithm which allows for the computation of reliable (sharp) bounds for the VaR of high-dimensional portfolios with dimensions d possibly in the several hundreds. We show that additional positive dependence information will typically not improve the upper bound substantially. In contrast higher order marginal information on the model, when available, may lead to strongly improved bounds. Several examples of practical relevance show how explicit VaR bounds can be obtained. These bounds can be interpreted as a measure of model uncertainty induced by possible dependence scenarios. ?? 2013 Elsevier B.V.},
 author = {Embrechts, Paul and Puccetti, Giovanni and Ruschendorf, Ludger},
 doi = {10.1016/j.jbankfin.2013.03.014},
 file = {:C\:/S/Library/Embrechts, Puccetti, Ruschendorf/2013_Model uncertainty and VaR aggregation.pdf:pdf},
 isbn = {3905543745},
 issn = {03784266},
 journal = {Journal of Banking and Finance},
 keywords = {Copula,Fr??chet class,Model uncertainity,Operational Risk,Positive dependence,Rearrangement algorithm,Risk Measures,Risk aggregation,Tails},
 mendeley-tags = {Risk Measures,Tails},
 number = {8},
 pages = {2750--2764},
 title = {{Model uncertainty and VaR aggregation}},
 volume = {37},
 year = {2013}
}

@article{Grubel1999,
 author = {Grubel, Rudolf and Hermesmeier, Renate},
 doi = {10.2143/AST.29.2.504611},
 file = {:C\:/S/Library/Grubel, Hermesmeier/1999_Computation of Compound Distributions I Aliasing Errors and Exponential Tilting(2).pdf:pdf},
 issn = {17831350},
 journal = {Astin Bulletin},
 keywords = {aliasing,and phrases,change of measure,fourier,random sums,ruin probabilities,total claim size distribution,transformation},
 number = {2},
 pages = {197--214},
 title = {{Computation of Compound Distributions I: Aliasing Errors and Exponential Tilting}},
 volume = {29},
 year = {1999}
}

@article{Heckman1983,
 abstract = {This paper discusses aggregate loss distributions from the perspective of collective risk theory. An accurate, efficient and practical algorithm is given for calculating cumulative probabilities and excess pure premiums. The input re-quired is the claim severity and claim count distributions. One of the main drawbacks of the collective risk model is the uncertainty of the parameters of the claim severity and claim count distributions. Modifi-cations of the collective risk model are proposed to deal with these problems. These modifications are incorporated into the algorithm. Examples are given illustrating the use of this algorithm. They include (1) calculating the pure premium for a policy with an aggregate limit; (2) calculating the pure premium of an aggregate stop-loss policy for group life insurance; and (3) calculating the insurance charge for a multi-line retrospective rating plan, including a line which is itself subject to an aggregate limit.},
 author = {Heckman, Philip E and Meyers, Glenn G},
 file = {:C\:/S/Library/Heckman, Meyers/1983_The calculation of aggregate loss distributions from claim severity and claim count distributions.pdf:pdf},
 journal = {Proceedings of the Casualty Actuarial Society},
 keywords = {Meyers},
 mendeley-tags = {Meyers},
 pages = {49--66},
 title = {{The calculation of aggregate loss distributions from claim severity and claim count distributions}},
 year = {1983}
}

@article{Hyndman1996,
 abstract = {There are a large number of different definitions used for sample quantiles in statistical computer packages. Often within the same package one definition will be used to compute a quantile explicitly, while other definitions may be used when producing a boxplot, a probability plot, or a QQ plot. We compare the most commonly implemented sample quantile definitions by writing them in a common notation and investigating their motivation and some of their properties. We argue that there is a need to adopt a standard definition for sample quantiles so that the same answers are produced by different packages and within each package. We conclude by recommending that the median-unbiased estimator be used because it has most of the desirable properties of a quantile estimator and can be defined independently of the underlying distribution. {\textcopyright} 1996 Taylor & Francis Group, LLC.},
 author = {Hyndman, Rob J. and Fan, Yanan},
 doi = {10.1080/00031305.1996.10473566},
 file = {:C\:/S/Library/Hyndman, Fan/1996_Sample Quantiles in Statistical Packages.pdf:pdf},
 issn = {15372731},
 journal = {American Statistician},
 keywords = {Percentiles,Quartiles,Sample quantiles,Statistical computer packages},
 number = {4},
 pages = {361--365},
 title = {{Sample Quantiles in Statistical Packages}},
 volume = {50},
 year = {1996}
}

@article{Ludwig1991,
 author = {Ludwig, B Y Stephen J},
 file = {:C\:/S/Library/Ludwig/1991_AN EXPOSURE RATING APPROACH TO PRICING(2).pdf:pdf},
 journal = {Proceedings of the Casualty Actuarial Society},
 title = {{AN EXPOSURE RATING APPROACH TO PRICING}},
 year = {1991}
}

@inproceedings{Mata2002,
 author = {Mata, Ana J and Ph, D and Fannin, Brian and Verheyen, Mark A},
 booktitle = {General Insurance Convention},
 file = {:C\:/S/Library/Mata et al/2002_Pricing Excess of Loss Treaty with Loss Sensitive Features An Exposure Rating Approach.pdf:pdf},
 title = {{Pricing Excess of Loss Treaty with Loss Sensitive Features: An Exposure Rating Approach}},
 year = {2002}
}

@article{Mildenhall2004,
 author = {Mildenhall, Stephen J},
 file = {:C\:/S/Library/Mildenhall/2004_A Note on the Myers and Read Capital Allocation Formula.pdf:pdf},
 issn = {10920277},
 journal = {North American Actuarial Journal},
 keywords = {capital and ownership structure,financing policy,g - financial economics,g220 - insurance,g320 -,insurance companies},
 number = {2},
 pages = {32--44},
 title = {{A Note on the Myers and Read Capital Allocation Formula}},
 url = {http://library.soa.org/library-pdf/naaj0402_3.pdf},
 volume = {8},
 year = {2004}
}

@article{Mildenhall2017b,
 annote = {Quick summary for Risks cover. 

Actuarial Geometry studies how the shape of an aggregate loss distribution changes as expected loss volume changes. The theory of Markov processes implies Levy processes are straight lines even though their distribution changes shape as expected losses increase. In contrast, an asset-return model retains a constant shape but represents a curved path. The difference is significant in the theory of risk measures and capital allocation, which are based on marginal changes in loss volume. In the figure the Levy process (red) is a great circle straight line whereas the asset model (blue) is a curved path. Growth along the two paths results in different measures of marginal risk (top right).},
 author = {Mildenhall, Stephen J},
 doi = {10.3390/risks5020031},
 file = {:C\:/S/Library/Mildenhall/2017_Actuarial Geometry.pdf:pdf},
 issn = {2227-9091},
 journal = {Risks},
 keywords = {capital allocation,capital determination,game,risk measure},
 number = {31},
 title = {{Actuarial Geometry}},
 volume = {5},
 year = {2017}
}

@article{Puccetti2012,
 abstract = {We propose a new algorithm to compute numerically sharp lower and upper bounds on the distribution of a function of d dependent random variables having fixed marginal distributions. Compared to the existing literature, the bounds are widely applicable, more accurate and more easily obtained. ?? 2011 Elsevier B.V. All rights reserved.},
 author = {Puccetti, Giovanni and Ruschendorf, Ludger},
 doi = {10.1016/j.cam.2011.10.015},
 file = {:C\:/S/Library/Puccetti, Ruschendorf/2012_Computation of sharp bounds on the distribution of a function of dependent risks.pdf:pdf},
 issn = {03770427},
 journal = {Journal of Computational and Applied Mathematics},
 keywords = {Bounds for dependent risks,Distribution functions,Rearrangements,Risk Measures,Tails},
 mendeley-tags = {Risk Measures,Tails},
 number = {7},
 pages = {1833--1840},
 publisher = {Elsevier B.V.},
 title = {{Computation of sharp bounds on the distribution of a function of dependent risks}},
 url = {http://dx.doi.org/10.1016/j.cam.2011.10.015},
 volume = {236},
 year = {2012}
}

@book{Strain1997,
 author = {Strain, Robert W.},
 publisher = {Robert W. Strain Publishing & Seminars, Incorporated},
 title = {{Reinsurance}},
 year = {1997}
}

@article{WangS1998,
 abstract = {This paperpresentsa set of tools formodeling and combining correlated risks. Various correlation struc- tures are generated using copula, common mixture, com- ponent, and distortion models. These correlation struc- tures are specified in terms of (i) the joint cumulative distribution function or (ii) the joint characteristic func- tion and lend themselves to efficient methods of aggre- gation by using Monte Carlo simulation or fast Fourier transform.},
 author = {Wang, S},
 file = {:C\:/S/Library/Wang/1998_Aggregation of correlated risk portfolios models and algorithms.pdf:pdf},
 journal = {Proceedings of the Casualty Actuarial society},
 keywords = {WangSS},
 mendeley-tags = {WangSS},
 pages = {848--939},
 title = {{Aggregation of correlated risk portfolios: models and algorithms}},
 url = {http://www.casact.com/pubs/proceed/proceed98/980848.pdf},
 year = {1998}
}
