@article{Acerbi2002b,
 abstract = {1000-2500 citations},
 author = {Acerbi, Carlo},
 doi = {10.1016/S0378-4266(02)00281-9},
 file = {:C\:/S/Library/Acerbi/2002_Spectral measures of risk A coherent representation of subjective risk aversion.pdf:pdf},
 issn = {03784266},
 journal = {Journal of Banking & Finance},
 keywords = {GSC,Risk Measures,coherence,conditional value-at-risk,expected shortfall,quan-,risk measure,value-at-risk},
 mendeley-tags = {GSC,Risk Measures},
 month = {jul},
 number = {7},
 pages = {1505--1518},
 title = {{Spectral measures of risk: A coherent representation of subjective risk aversion}},
 url = {http://linkinghub.elsevier.com/retrieve/pii/S0378426602002819},
 volume = {26},
 year = {2002}
}

@article{Bodoff2007,
 author = {Bodoff, Neil M.},
 file = {:C\:/S/Library/Bodoff/2007_Capital Allocation by Percentile Layer.pdf:pdf},
 journal = {Variance},
 keywords = {capital allocation,enterprise risk,management,percentile layer of capital,risk load,risk-adjusted profitability,value at risk},
 number = {1},
 pages = {13--30},
 title = {{Capital Allocation by Percentile Layer}},
 volume = {3},
 year = {2007}
}

@book{Borwein2010,
 author = {Borwein, Jonathan M and Vanderwerff, Jon D},
 file = {:C\:/S/Library/Borwein, Vanderwerff/2010_Convex Functions - Construction, Characterizations and Counterexamples.pdf:pdf},
 isbn = {9780521850056},
 publisher = {Cambridge University Press},
 title = {{Convex Functions - Construction, Characterizations and Counterexamples}},
 year = {2010}
}

@book{Bowers1997,
 author = {Bowers, Newton and Gerber, Hans and Hickman, James and Jones, Donald and Nesbitt, Cecil},
 doi = {10.2307/253313},
 file = {:C\:/S/Library/Bowers et al/1997_Actuarial Mathematics.pdf:pdf},
 issn = {00224367},
 keywords = {Book},
 mendeley-tags = {Book},
 publisher = {Society of Actuaries},
 title = {{Actuarial Mathematics}},
 year = {1997}
}

@article{Brown1983,
 abstract = {The asymptotic formula for the variance of a percentile estimate is inversely proportional to the square of the probability density function evaluated at that percentile. In this note we show, for small and moderate sample sizes, that the estimate of the variance can have a moderate to large coefficient of variation even when the form of the density is known. When the density must be estimated empirically, the coefficient of variation increases substantially. We conclude that the estimate of the variance should not be used in either confidence interval estimation or hypothesis testing except for very large sample sizes. {\textcopyright} 1983.},
 author = {Brown, Morton B. and Wolfe, Robert A.},
 doi = {10.1016/0167-9473(83)90088-9},
 file = {:C\:/S/Library/Brown, Wolfe/1983_Estimation of the variance of percentile estimates.pdf:pdf},
 issn = {01679473},
 journal = {Computational Statistics and Data Analysis},
 keywords = {Estimation,Percentile estimates},
 number = {C},
 pages = {167--174},
 title = {{Estimation of the variance of percentile estimates}},
 volume = {1},
 year = {1983}
}

@article{Butsic1994,
 abstract = {Regulators have recently adopted a risk-based capital formula for property-liability insurers. This article develops practical methods for setting risk-based capital standards using the expected policyholder deficit as the solvency measure. The analysis considers the stochastic nature of insurance risk, using market valuation to remove measurement bias, and finds that a proper time horizon is the period between risk-based capital evaluations. The present value of the expected policyholder deficit is shown to be equivalent to a financial option implicitly given by the policyholders. Finally, covariance of risk elements is considered, deriving a simple square root rule.},
 author = {Butsic, Robert P},
 file = {:C\:/S/Library/Butsic/1994_Solvency Measurement for Property-Liability Risk-Based Capital Applications.pdf:pdf},
 isbn = {00224367},
 journal = {The Journal of Risk and Insurance},
 keywords = {Risk Measures},
 mendeley-tags = {Risk Measures},
 number = {4},
 pages = {656--690},
 pmid = {9502081283},
 title = {{Solvency Measurement for Property-Liability Risk-Based Capital Applications}},
 url = {http://www.jstor.org/stable/253643%5Cnhttp://www.jstor.org/page/},
 volume = {61},
 year = {1994}
}

@article{Campi2013,
 abstract = {In this article, we characterize efficient portfolios, i.e. portfolios which are optimal for at least one rational agent, in a very general multi-currency financial market model with proportional transaction costs. In our setting, transaction costs may be random, time-dependent, have jumps and the preferences of the agents are modeled by multivariate expected utility functions. We provide a complete characterization of efficient portfolios, generalizing earlier results of Dybvig (Rev Financ Stud 1:67-88, 1988) and Jouini and Kallal (J Econ Theory 66: 178-197, 1995). We basically show that a portfolio is efficient if and only if it is cyclically anticomonotonic with respect to at least one consistent price system that prices it. Finally, we introduce the notion of utility price of a given contingent claim as the minimal amount of a given initial portfolio allowing any agent to reach the claim by trading, and give a dual representation of it as the largest proportion of the market price necessary for all agents to reach the same expected utility level. {\textcopyright} 2013 Springer-Verlag Berlin Heidelberg.},
 author = {Campi, Luciano and Jouini, Ely{\`{e}}s and Porte, Vincent},
 doi = {10.1007/s11579-013-0099-4},
 file = {:C\:/S/Library/Campi, Jouini, Porte/2013_Efficient portfolios in financial markets with proportional transaction costs.pdf:pdf},
 issn = {18629679},
 journal = {Mathematics and Financial Economics},
 keywords = {Cyclic anticomonotonicity,Duality,Efficient portfolios,Jouini,Proportional transaction costs,Utility maximization,Utility price},
 mendeley-tags = {Jouini},
 number = {3},
 pages = {281--304},
 title = {{Efficient portfolios in financial markets with proportional transaction costs}},
 volume = {7},
 year = {2013}
}

@article{Carlier2003,
 abstract = {This paper characterizes the core of a differentiable convex distortion of a probability measure on a nonatomic space by identifying it with the set of densities which dominate the derivative of the distortion, for second order stochastic dominance. The densities that have the same distribution as the derivative of the distortion are the extreme points of the core. These results are applied to the differentiability of a Yaari's or Rank Dependent Expected utility function. The superdifferential of a Choquet integral at any point is fully characterized. Examples of use of these results in simple models where some agent is a RDEU maximizer are given. {\textcopyright} 2003 Elsevier Science (USA). All rights reserved.},
 author = {Carlier, G. and Dana, R. A.},
 doi = {10.1016/S0022-0531(03)00122-4},
 file = {:C\:/S/Library/Carlier, Dana/2003_Core of convex distortions of a probability.pdf:pdf},
 isbn = {0022-0531},
 issn = {00220531},
 journal = {Journal of Economic Theory},
 keywords = {Capacity,Convex distortion,Core,Derivative and superdifferential of a Choquet inte,Risk Measures},
 mendeley-tags = {Risk Measures},
 number = {2},
 pages = {199--222},
 title = {{Core of convex distortions of a probability}},
 volume = {113},
 year = {2003}
}

@article{Clark2004,
 abstract = {A Primer on the Exponential Family of Distributions},
 author = {Clark, David R and Thayer, Charles A},
 file = {:C\:/S/Library/Clark, Thayer/2004_A primer on the exponential family of distributions.pdf:pdf},
 journal = {Casualty Actuarial Society Spring Forum},
 pages = {117--148},
 title = {{A primer on the exponential family of distributions}},
 url = {papers2://publication/uuid/C7FF0B8F-F767-4F09-9714-F0D3711A30D8},
 year = {2004}
}

@book{Conover1999,
 author = {Conover, W J},
 edition = {Third},
 publisher = {John Wiley and Sons},
 title = {{Practical nonparametric statistics}},
 year = {1999}
}

@article{Culp2009,
 author = {Culp, Christopher L. and O'Donnell, Kevin J.},
 doi = {10.1108/15265940911001367},
 file = {:C\:/S/Library/Culp, O'Donnell/2009_Catastrophe reinsurance and risk capital in the wake of the credit crisis.pdf:pdf},
 issn = {1526-5943},
 journal = {The Journal of Risk Finance},
 keywords = {credit,finance,paper type conceptual paper,reinsurance,risk management,the journal of risk},
 number = {5},
 pages = {430--459},
 title = {{Catastrophe reinsurance and risk capital in the wake of the credit crisis}},
 url = {http://www.emeraldinsight.com/10.1108/15265940911001367},
 volume = {10},
 year = {2009}
}

@article{Cummins2005,
 author = {Cummins, J. David and Phillips, Richard D.},
 file = {:C\:/S/Library/Cummins, Phillips/2005_Estimating the Cost of Equity Capital for Property-Liability Insurers.pdf:pdf},
 journal = {Journal of Risk and Insurance},
 keywords = {Cummins},
 mendeley-tags = {Cummins},
 number = {3},
 pages = {441--478},
 title = {{Estimating the Cost of Equity Capital for Property-Liability Insurers}},
 url = {http://onlinelibrary.wiley.com/doi/10.1111/j.1539-6975.2005.00132.x/full},
 volume = {72},
 year = {2005}
}

@article{Delbaen2000,
 abstract = {Sculoa notes, from his website https://people.math.ethz.ch/$\sim$delbaen/},
 author = {Delbaen, Freddy},
 doi = {10.1007/BF02809088},
 file = {:C\:/S/Library/Delbaen/2000_Coherent risk measures (Pisa Notes).pdf:pdf},
 issn = {0012-0200},
 journal = {Pisa Notes},
 keywords = {Delbaen,Risk Measures},
 mendeley-tags = {Delbaen,Risk Measures},
 number = {4},
 pages = {733--739},
 title = {{Coherent risk measures (Pisa Notes)}},
 volume = {24},
 year = {2000}
}

@article{Denault2001,
 abstract = {567 citations},
 author = {Denault, Michel},
 doi = {10.21314/jor.2001.053},
 file = {:C\:/S/Library/Denault/2001_Coherent allocation of risk capital.pdf:pdf},
 issn = {14651211},
 journal = {The Journal of Risk},
 keywords = {Risk Measures,allocation of capital,aumann-shapley,coherent risk measure,formance measure,fuzzy games,game theory,risk-adjusted per-,shapley value},
 mendeley-tags = {Risk Measures},
 number = {1},
 pages = {1--34},
 title = {{Coherent allocation of risk capital}},
 url = {ftp://ftp.sam.math.ethz.ch/pub/risklab/papers/CoherentAllocation.pdf},
 volume = {4},
 year = {2001}
}

@article{Denuit2012,
 abstract = {Using a standard reduction argument based on conditional expectations, this paper argues that risk sharing is always beneficial (with respect to convex order or second degree stochastic dominance) provided the risk-averse agents share the total losses appropriately (whatever the distribution of the losses, their correlation structure and individual degrees of risk aversion). Specifically, all agents hand their individual losses over to a pool and each of them is liable for the conditional expectation of his own loss given the total loss of the pool. We call this risk sharing mechanism the conditional mean risk sharing. If all the conditional expectations involved are non-decreasing functions of the total loss then the conditional mean risk sharing is shown to be Pareto-optimal. Explicit expressions for the individual contributions to the pool are derived in some special cases of interest: independent and identically distributed losses, comonotonic losses, and mutually exclusive losses. In particular, conditions under which this payment rule leads to a comonotonic risk sharing are examined. {\textcopyright} 2012 Elsevier B.V.},
 author = {Denuit, Michel and Dhaene, Jan},
 doi = {10.1016/j.insmatheco.2012.04.005},
 file = {:C\:/S/Library/Denuit, Dhaene/2012_Convex order and comonotonic conditional mean risk sharing.pdf:pdf},
 issn = {01676687},
 journal = {Insurance: Mathematics and Economics},
 keywords = {Comonotonicity,Conditional expectation,Pareto-optimality,Risk sharing,Stochastic orders},
 number = {2},
 pages = {265--270},
 publisher = {Elsevier B.V.},
 title = {{Convex order and comonotonic conditional mean risk sharing}},
 url = {http://dx.doi.org/10.1016/j.insmatheco.2012.04.005},
 volume = {51},
 year = {2012}
}

@unpublished{Denuit2020e,
 author = {Denuit, Michel M. and Robert, C Y},
 file = {:C\:/S/Library/Denuit, Robert/2020_Risk Reduction by Conditional Mean Risk Sharing With Application to Collaborative Insurance.pdf:pdf},
 institution = {UC Louvain},
 series = {Discussion Paper},
 title = {{Risk Reduction by Conditional Mean Risk Sharing With Application to Collaborative Insurance}},
 year = {2020}
}

@article{DeWaegenaere2003,
 abstract = {Was refd as 2006 Choquet pricing and in particular Wang's premium principle, have recently been put forward as an alternative to traditional pricing principles in finance and insurance. With Choquet pricing, the price of an insurance contract or financial asset equals the Choquet integral of the corresponding payoff with respect to a concave sub-additive measure. Since the resulting pricing rule is non-linear, existing theories do not provide an answer to the question of whether equilibrium exists. We introduce a general equilibrium model that allows for non-linearity, and show that Choquet pricing is consistent with general equilibrium. {\textcopyright} 2003 Elsevier Science B.V. All rights reserved.},
 author = {{De Waegenaere}, Anja and Kast, Robert and Lapied, Andre},
 doi = {10.1016/S0167-6687(03)00116-1},
 file = {:C\:/S/Library/De Waegenaere, Kast, Lapied/2003_Choquet pricing and equilibrium.pdf:pdf},
 issn = {01695002},
 journal = {Insurance: Mathematics and Economics},
 keywords = {Asset pricing,Choquet integrals,Equilibrium,Insurance pricing},
 pages = {359--370},
 title = {{Choquet pricing and equilibrium}},
 volume = {32},
 year = {2003}
}

@article{Dhaene2012b,
 author = {Dhaene, Jan and Kukush, Alexander and Linders, Daniel and Tang, Qihe},
 file = {:C\:/S/Library/Dhaene et al/2012_Remarks on quantiles and distortion risk measures.pdf:pdf},
 journal = {European Actuarial Journal},
 keywords = {comonotonicity,distorted expectation,distortion risk measure,tvar},
 number = {2},
 pages = {319--328},
 title = {{Remarks on quantiles and distortion risk measures}},
 volume = {2},
 year = {2012}
}

@article{Embrechts2009a,
 abstract = {Numerical evaluation of compound distributions is an important task in insurance mathematics and quantitative risk management. In practice, both recursive methods as well as transform based techniques are widely used. We give a survey of these tools, point out the respective merits and provide some numerical examples. {\textcopyright} 2008 Springer-Verlag.},
 author = {Embrechts, Paul and Frei, Marco},
 doi = {10.1007/s00186-008-0249-2},
 file = {:C\:/S/Library/Embrechts, Frei/2009_Panjer recursion versus FFT for compound distributions.pdf:pdf},
 issn = {14322994},
 journal = {Mathematical Methods of Operations Research},
 keywords = {Compound distributions,Fast Fourier transform,Panjer recursion,Risk management},
 number = {3},
 pages = {497--508},
 title = {{Panjer recursion versus FFT for compound distributions}},
 volume = {69},
 year = {2009}
}

@article{Embrechts2013,
 abstract = {Despite well-known shortcomings as a risk measure, Value-at-Risk (VaR) is still the industry and regulatory standard for the calculation of risk capital in banking and insurance. This paper is concerned with the numerical estimation of the VaR for a portfolio position as a function of different dependence scenarios on the factors of the portfolio. Besides summarizing the most relevant analytical bounds, including a discussion of their sharpness, we introduce a numerical algorithm which allows for the computation of reliable (sharp) bounds for the VaR of high-dimensional portfolios with dimensions d possibly in the several hundreds. We show that additional positive dependence information will typically not improve the upper bound substantially. In contrast higher order marginal information on the model, when available, may lead to strongly improved bounds. Several examples of practical relevance show how explicit VaR bounds can be obtained. These bounds can be interpreted as a measure of model uncertainty induced by possible dependence scenarios. ?? 2013 Elsevier B.V.},
 author = {Embrechts, Paul and Puccetti, Giovanni and Ruschendorf, Ludger},
 doi = {10.1016/j.jbankfin.2013.03.014},
 file = {:C\:/S/Library/Embrechts, Puccetti, Ruschendorf/2013_Model uncertainty and VaR aggregation.pdf:pdf},
 isbn = {3905543745},
 issn = {03784266},
 journal = {Journal of Banking and Finance},
 keywords = {Copula,Fr??chet class,Model uncertainity,Operational Risk,Positive dependence,Rearrangement algorithm,Risk Measures,Risk aggregation,Tails},
 mendeley-tags = {Risk Measures,Tails},
 number = {8},
 pages = {2750--2764},
 title = {{Model uncertainty and VaR aggregation}},
 volume = {37},
 year = {2013}
}

@book{feller71,
 abstract = {The exponential and the uniform densities; Special densities. Randomization; Densities in higher dimensions. Normal densities and processes; Probability measures and spaces; Probability distributions in Rr; A survey of some important distributions and processes; Laws of large numbers. Aplications in analysis; The basic limit theorems; Infinitely divisible distributions and semi-groups; Markov processes and semi-groups; Renewal theory; Random walks in R1; Laplace transforms. Tauberian theorems. Resolvents; Aplications of Laplace transforms; Characteristic functions; Expansions related to the central limit theorem; Infinitely divisible distributions; Applications of Fourier methods to ramdom walks; harmonic analysis; Answers to problems.},
 author = {Feller, William},
 edition = {Second},
 isbn = {0471257095},
 pages = {669},
 publisher = {J. Wiley and Sons},
 title = {{An Introduction to Probability Theory and its Applications, Volume 2}},
 year = {1971}
}

@book{Follmer2011,
 author = {F{\"{o}}llmer, Hans and Schied, Alexander},
 edition = {Third Edit},
 publisher = {Walter de Gruyter},
 title = {{Stochastic finance: an introduction in discrete time}},
 year = {2011}
}

@article{Grundl2007,
 author = {Grundl, Helmut and Schmeiser, Hato},
 file = {:C\:/S/Library/Grundl, Schmeiser/2007_Capital allocation for insurance companies---What Good Is It.pdf:pdf},
 journal = {Journal of Risk and Insurance},
 keywords = {Risk Measures},
 mendeley-tags = {Risk Measures},
 number = {2},
 title = {{Capital allocation for insurance companies---What Good Is It?}},
 url = {http://www.jstor.org/stable/2691539},
 volume = {74},
 year = {2007}
}

@article{Heckman1983,
 abstract = {This paper discusses aggregate loss distributions from the perspective of collective risk theory. An accurate, efficient and practical algorithm is given for calculating cumulative probabilities and excess pure premiums. The input re-quired is the claim severity and claim count distributions. One of the main drawbacks of the collective risk model is the uncertainty of the parameters of the claim severity and claim count distributions. Modifi-cations of the collective risk model are proposed to deal with these problems. These modifications are incorporated into the algorithm. Examples are given illustrating the use of this algorithm. They include (1) calculating the pure premium for a policy with an aggregate limit; (2) calculating the pure premium of an aggregate stop-loss policy for group life insurance; and (3) calculating the insurance charge for a multi-line retrospective rating plan, including a line which is itself subject to an aggregate limit.},
 author = {Heckman, Philip E and Meyers, Glenn G},
 file = {:C\:/S/Library/Heckman, Meyers/1983_The calculation of aggregate loss distributions from claim severity and claim count distributions.pdf:pdf},
 journal = {Proceedings of the Casualty Actuarial Society},
 keywords = {Meyers},
 mendeley-tags = {Meyers},
 pages = {49--66},
 title = {{The calculation of aggregate loss distributions from claim severity and claim count distributions}},
 year = {1983}
}

@article{Hyndman1996,
 abstract = {There are a large number of different definitions used for sample quantiles in statistical computer packages. Often within the same package one definition will be used to compute a quantile explicitly, while other definitions may be used when producing a boxplot, a probability plot, or a QQ plot. We compare the most commonly implemented sample quantile definitions by writing them in a common notation and investigating their motivation and some of their properties. We argue that there is a need to adopt a standard definition for sample quantiles so that the same answers are produced by different packages and within each package. We conclude by recommending that the median-unbiased estimator be used because it has most of the desirable properties of a quantile estimator and can be defined independently of the underlying distribution. {\textcopyright} 1996 Taylor & Francis Group, LLC.},
 author = {Hyndman, Rob J. and Fan, Yanan},
 doi = {10.1080/00031305.1996.10473566},
 file = {:C\:/S/Library/Hyndman, Fan/1996_Sample Quantiles in Statistical Packages.pdf:pdf},
 issn = {15372731},
 journal = {American Statistician},
 keywords = {Percentiles,Quartiles,Sample quantiles,Statistical computer packages},
 number = {4},
 pages = {361--365},
 title = {{Sample Quantiles in Statistical Packages}},
 volume = {50},
 year = {1996}
}

@article{Ibragimov2010,
 author = {Ibragimov, Rustam and Jaffee, Dwight and Walden, Johan},
 doi = {10.1111/j.1539-6975.2010.01353.x},
 file = {:C\:/S/Library/Ibragimov, Jaffee, Walden/2010_Pricing and Capital Allocation for Multiline Insurance Firms.pdf:pdf},
 issn = {00224367},
 journal = {Journal of Risk and Insurance},
 keywords = {Risk Measures},
 mendeley-tags = {Risk Measures},
 month = {mar},
 number = {3},
 pages = {551--578},
 title = {{Pricing and Capital Allocation for Multiline Insurance Firms}},
 url = {http://doi.wiley.com/10.1111/j.1539-6975.2010.01353.x},
 volume = {77},
 year = {2010}
}

@book{Jorgensen1997,
 author = {J{\o}rgensen, Bent},
 file = {:C\:/S/Library/J{\o}rgensen/1997_The theory of dispersion models(2).pdf:pdf},
 publisher = {CRC Press},
 title = {{The theory of dispersion models}},
 year = {1997}
}

@article{Jouini2001,
 abstract = {We provide a price characterization of efficient contingent claims - that is, chosen by at least a rational agent - in multiperiod economies with market frictions. Frictions include market incompleteness, transaction costs, short-selling, and borrowing costs. We characterize the inefficiency cost of a trading strategy - its required investment minus the largest amount necessary to obtain the same utility level - and we propose a measure of portfolio performance. We show that arbitrage bounds cannot be tightened based on efficiency without restricting preferences or endowments. We observe common investment strategies becoming inefficient with market frictions and others rationalized by them.},
 author = {Jouini, Ely{\`{e}}s and Kallal, H{\'{e}}di},
 doi = {10.1093/rfs/14.2.343},
 file = {:C\:/S/Library/Jouini, Kallal/2001_Efficient trading strategies in the presence of market frictions.pdf:pdf},
 issn = {08939454},
 journal = {Review of Financial Studies},
 keywords = {Jouini},
 mendeley-tags = {Jouini},
 number = {2},
 pages = {343--369},
 title = {{Efficient trading strategies in the presence of market frictions}},
 volume = {14},
 year = {2001}
}

@article{Kusuoka2001,
 abstract = {500-1000 citations},
 author = {Kusuoka, Shigeo},
 file = {:C\:/S/Library/Kusuoka/2001_On law invariant coherent risk measures.pdf:pdf},
 journal = {Advances in Mathematical Economics},
 keywords = {GSC,Risk Measures},
 mendeley-tags = {GSC,Risk Measures},
 pages = {83--95},
 title = {{On law invariant coherent risk measures}},
 url = {http://link.springer.com/chapter/10.1007/978-4-431-67891-5_4},
 volume = {3},
 year = {2001}
}

@article{Major2018,
 abstract = {This paper extends the evaluation and allocation of distortion risk measures to apply to arbitrary homogeneous components of a portfolio (“financial derivatives,” e.g. reinsurance recovery, of primitive portfolio components, e.g. lines of business). It is argued that the allocation of the portfolio measure to the financial derivative takes the usual form of (distortion-) weighted “co-measure” expectation. Due to homogeneity, the allocation of the derivative's value to further subcomponents (ultimately, the primitive elements of the portfolio), following Aumann-Shapley, is the exposure gradient. However, the gradient in this case consists of two terms. The first is the familiar distorted expectation of the gradient of the component with respect to the subcomponent. The second term involves the conditional covariance of the component with the subcomponent. Sufficient conditions for this second term to vanish are provided. A method for estimating the second component in a simulation framework is proposed.},
 author = {Major, John A.},
 doi = {10.2139/ssrn.2972955},
 file = {:C\:/S/Library/Major/2018_Distortion Measures on Homogeneous Financial Derivatives.pdf:pdf},
 issn = {1556-5068},
 journal = {Insurance: Mathematics and Economics},
 keywords = {Major,Risk Measures,aumann-shapley,c71,capital allocation,d81,distortion measures,financial derivatives,g22,jel classifications,reinsurance},
 mendeley-tags = {Major,Risk Measures},
 pages = {82--91},
 publisher = {Elsevier B.V.},
 title = {{Distortion Measures on Homogeneous Financial Derivatives}},
 url = {http://www.ssrn.com/abstract=2972955 http://linkinghub.elsevier.com/retrieve/pii/S0167668717303384},
 volume = {79},
 year = {2018}
}

@article{Major2020,
 abstract = {We analyze multiline pricing and capital allocation in equilibrium no-arbitrage markets. Existing theories often assume a perfect complete market, but when pricing is linear, there is no diversification benefit from risk pooling and therefore no role for insurance companies. Instead of a perfect market, we assume a non-additive distortion pricing functional and the principle of equal priority of payments in default. Under these assumptions, we derive a canonical allocation of premium and margin, with properties that merit the name the natural allocation. The natural allocation gives non-negative margins to all independent lines for default-free insurance but can exhibit negative margins for low-risk lines under limited liability. We introduce novel conditional expectation measures of relative risk within a portfolio and use them to derive simple, intuitively appealing expressions for risk margins and capital allocations. We give a unique capital allocation consistent with our law invariant pricing functional. Such allocations produce returns that vary by line, in contrast to many other approaches. Our model provides a bridge between the theoretical perspective that there should be no compensation for bearing diversifiable risk and the empirical observation that more risky lines fetch higher margins relative to subjective expected values.},
 archiveprefix = {arXiv},
 arxivid = {2008.12427},
 author = {Major, John A. and Mildenhall, Stephen J.},
 eprint = {2008.12427},
 file = {:C\:/S/Library/Major, Mildenhall/2020_Pricing and Capital Allocation for Multiline Insurance Firms With Finite Assets in an Imperfect Market.pdf:pdf},
 journal = {Arxiv},
 keywords = {Major},
 mendeley-tags = {Major},
 number = {2008.12427},
 pages = {1--33},
 title = {{Pricing and Capital Allocation for Multiline Insurance Firms With Finite Assets in an Imperfect Market}},
 url = {http://arxiv.org/abs/2008.12427},
 year = {2020}
}

@article{Mango2005a,
 author = {Mango, Donald},
 file = {:C\:/S/Library/Mango/2005_Insurance Capital as a Shared Asset.pdf:pdf},
 journal = {Astin Bulletin},
 keywords = {Risk Measures},
 mendeley-tags = {Risk Measures},
 number = {2},
 pages = {471--486},
 title = {{Insurance Capital as a Shared Asset}},
 url = {https://www.beanactuary.com/pubs/forum/06fforum/577.pdf},
 volume = {35},
 year = {2005}
}

@article{Mango2013,
 author = {Mango, Donald and Major, John and Adler, Avraham and Bunick, Claude},
 file = {:C\:/S/Library/Mango et al/2013_Capital Tranching A RAROC Approach to Assessing Reinsurance Cost Effectiveness.pdf:pdf},
 journal = {Variance},
 keywords = {Major,capital consumption,raroc,reinsurance cost effectiveness,risk management,rorac},
 mendeley-tags = {Major},
 number = {September},
 pages = {82--91},
 title = {{Capital Tranching: A RAROC Approach to Assessing Reinsurance Cost Effectiveness}},
 url = {http://www.actuaries.org.uk/sites/all/files/documents/pdf/capital-tranching-raroc-approach-assessing-reinsurance-cost-effectiveness.pdf},
 volume = {7},
 year = {2013}
}

@article{Meyers1996,
 author = {Meyers, Glenn G},
 file = {:C\:/S/Library/Meyers/1996_The competitive market equilibrium risk load formula for catastrophe ratemaking.pdf:pdf},
 journal = {PCAS},
 keywords = {Meyers},
 mendeley-tags = {Meyers},
 pages = {563--600},
 title = {{The competitive market equilibrium risk load formula for catastrophe ratemaking}},
 year = {1996}
}

@article{Mildenhall2005a,
 author = {Mildenhall, Stephen J},
 file = {:C\:/S/Library/Mildenhall/2005_Correlation and Aggregate Loss Distributions With An Emphasis On The Iman-Conover Method.pdf:pdf},
 journal = {Casualty Actuarial Society Forum},
 title = {{Correlation and Aggregate Loss Distributions With An Emphasis On The Iman-Conover Method}},
 volume = {Winter},
 year = {2005}
}

@article{Mildenhall2017b,
 annote = {Quick summary for Risks cover. 

Actuarial Geometry studies how the shape of an aggregate loss distribution changes as expected loss volume changes. The theory of Markov processes implies Levy processes are straight lines even though their distribution changes shape as expected losses increase. In contrast, an asset-return model retains a constant shape but represents a curved path. The difference is significant in the theory of risk measures and capital allocation, which are based on marginal changes in loss volume. In the figure the Levy process (red) is a great circle straight line whereas the asset model (blue) is a curved path. Growth along the two paths results in different measures of marginal risk (top right).},
 author = {Mildenhall, Stephen J},
 doi = {10.3390/risks5020031},
 file = {:C\:/S/Library/Mildenhall/2017_Actuarial Geometry.pdf:pdf},
 issn = {2227-9091},
 journal = {Risks},
 keywords = {capital allocation,capital determination,game,risk measure},
 number = {31},
 title = {{Actuarial Geometry}},
 volume = {5},
 year = {2017}
}

@article{Mildenhall2022,
 author = {Mildenhall, Stephen J.},
 doi = {10.1016/j.insmatheco.2022.04.006},
 file = {:C\:/S/Library/Mildenhall/2022_Similar Risks Have Similar Prices A Useful and Exact Quantification.pdf:pdf},
 issn = {01676687},
 journal = {Insurance: Mathematics and Economics},
 pages = {203--210},
 publisher = {Elsevier B.V.},
 title = {{Similar Risks Have Similar Prices: A Useful and Exact Quantification}},
 url = {https://doi.org/10.1016/j.insmatheco.2022.04.006},
 volume = {105},
 year = {2022}
}

@incollection{Myers1987,
 author = {Myers, Stewart C and Cohn, Richard A},
 booktitle = {Fair Rate of Return in Property-Liability Insurance},
 pages = {55--78},
 publisher = {Springer},
 title = {{A discounted cash flow approach to property-liability insurance rate regulation}},
 year = {1987}
}

@article{Myers2001,
 abstract = {250-500 citations},
 author = {Myers, Stewart C and {Read Jr.}, James A},
 file = {:C\:/S/Library/Myers, Read Jr/2001_Capital allocation for insurance companies.pdf:pdf},
 journal = {Journal of Risk and Insurance},
 keywords = {GSC,Risk Measures},
 mendeley-tags = {GSC,Risk Measures},
 number = {4},
 pages = {545--580},
 title = {{Capital allocation for insurance companies}},
 url = {http://www.jstor.org/stable/2691539},
 volume = {68},
 year = {2001}
}

@article{Phillips1998,
 abstract = {This paper uses a contingent claims framework to develop a financial pricing model of insurance that overcomes one of the main shortcomings of previous models - the inability to price insurance by line in a multiple line insurer subject to default risk. The model predicts prices will vary across firms depending upon firm default risk, but within a given insurer prices should not vary after controlling for line-specific liability growth rates. We also analyze an important qualification to this result for insurance groups, where several insurer subsidiaries are owned by a primary insurer or holding company. Empirical tests using data on publicly traded property-liability insurers support the hypotheses: prices vary across firms depending upon overall-firm default risk and the concentration of business among subsidiaries; but within a given firm, prices do not vary by line after adjusting for line-specific liability growth rates.},
 annote = {From Duplicate 1 (Financial Pricing of Insurance in the Multiple-Line Insurance Company - Phillips, Richard D.; Cummins, J. David; Allen, Franklin)

From Duplicate 1 ( 

Financial Pricing of Insurance in the Multiple-Line Insurance Company

- Phillips, Richard D RD; Cummins, JD David; Allen, Franklin )




From Duplicate 2 ( 


Financial pricing of insurance in the multiple-line insurance company


- Phillips, RD; Cummins, JD; Allen, Franklin )



here are so e notes on this very important paper.









From Duplicate 2 ( 

Financial Pricing of Insurance in the Multiple-Line Insurance Company

- Phillips, Richard D RD; Cummins, JD David; Allen, Franklin )




From Duplicate 1 ( 


Financial Pricing of Insurance in the Multiple-Line Insurance Company


- Phillips, Richard D RD; Cummins, JD David; Allen, Franklin )




From Duplicate 2 ( 


Financial pricing of insurance in the multiple-line insurance company


- Phillips, RD; Cummins, JD; Allen, Franklin )



here are so e notes on this very important paper.









From Duplicate 2 ( 


Financial pricing of insurance in the multiple-line insurance company


- Phillips, RD; Cummins, JD; Allen, Franklin )



here are so e notes on this very important paper.},
 author = {Phillips, Richard D. and Cummins, J. David and Allen, Franklin},
 doi = {10.2307/253804},
 file = {:C\:/S/Library/Phillips, Cummins, Allen/1998_Financial Pricing of Insurance in the Multiple-Line Insurance Company(3).pdf:pdf},
 issn = {00224367},
 journal = {Journal of Risk and Insurance},
 keywords = {Cummins,Risk Measures},
 mendeley-tags = {Cummins,Risk Measures},
 number = {4},
 pages = {597--636},
 title = {{Financial Pricing of Insurance in the Multiple-Line Insurance Company}},
 url = {http://www.jstor.org/stable/253804 http://www.jstor.org/stable/10.2307/253804 http://www.jstor.org/stable/253804%5Cnhttp://www.jstor.org/stable/10.2307/253804},
 volume = {65},
 year = {1998}
}

@article{Puccetti2012,
 abstract = {We propose a new algorithm to compute numerically sharp lower and upper bounds on the distribution of a function of d dependent random variables having fixed marginal distributions. Compared to the existing literature, the bounds are widely applicable, more accurate and more easily obtained. ?? 2011 Elsevier B.V. All rights reserved.},
 author = {Puccetti, Giovanni and Ruschendorf, Ludger},
 doi = {10.1016/j.cam.2011.10.015},
 file = {:C\:/S/Library/Puccetti, Ruschendorf/2012_Computation of sharp bounds on the distribution of a function of dependent risks.pdf:pdf},
 issn = {03770427},
 journal = {Journal of Computational and Applied Mathematics},
 keywords = {Bounds for dependent risks,Distribution functions,Rearrangements,Risk Measures,Tails},
 mendeley-tags = {Risk Measures,Tails},
 number = {7},
 pages = {1833--1840},
 publisher = {Elsevier B.V.},
 title = {{Computation of sharp bounds on the distribution of a function of dependent risks}},
 url = {http://dx.doi.org/10.1016/j.cam.2011.10.015},
 volume = {236},
 year = {2012}
}

@article{Saumard2014,
 abstract = {We review and formulate results concerning log-concavity and strong-log-concavity in both discrete and continuous settings. We show how preservation of log-concavity and strong log-concavity on R under convolution follows from a fundamental monotonicity result of Efron (1965). We provide a new proof of Efron's theorem using the recent asymmetric Brascamp-Lieb inequality due to Otto and Menz (2013). Along the way we review connections between log-concavity and other areas of mathematics and statistics, including concentration of measure, log-Sobolev inequalities, convex geometry, MCMC algorithms, Laplace approximations, and machine learning.},
 archiveprefix = {arXiv},
 arxivid = {1404.5886},
 author = {Saumard, Adrien and Wellner, Jon A.},
 doi = {10.1214/14-SS107},
 eprint = {1404.5886},
 file = {:C\:/S/Library/Saumard, Wellner/2014_Log-concavity and strong log-concavity a review.pdf:pdf},
 issn = {19357516},
 journal = {Statistics Surveys},
 keywords = {Concave,Convex,Convolution,Inequalities,Log-concave,Monotone,Preservation,Strong log-concave,Tails},
 mendeley-tags = {Tails},
 pages = {45--114},
 title = {{Log-concavity and strong log-concavity: a review}},
 volume = {8},
 year = {2014}
}

@book{Shapiro2009,
 abstract = {The readers familiar with the area of optimization can easily name several classes of optimization problems, for which advanced theoretical results exist and efficient numerical\nmethods have been found. In that respect we can mention linear programming, quadratic programming, convex optimization, nonlinear optimization, etc. Stochastic programming sounds similar, but no specific formulation plays the role of the generic stochastic programming problem. The presence of random quantities in the model under consideration opens the door to wealth of different problem settings, reflecting different aspects of the applied problem at hand. The main purpose of this chapter is to illustrate the main approaches that can be followed when developing a suitable stochastic optimization model. For the purpose of presentation, these are very simplified versions of problems encountered in practice, but we hope that they will still help us to convey our main message.},
 annote = {From Duplicate 1 (Lectures on Stochastic Programming - Shapiro, Alexander; Dentcheva, Darinka; Ruszczy{\'{n}}ski, Andrzej)

Chapter 6: very nice intro to AVaR motivating why it is >= VaR (pp.262--)

Note (6.74) description of partial AVaR = measures such that AVaR = E_Q(X)... very nice!

Ex 6.18 = mean deviation risk measure order p
Ex 6.19 = mean upper semi deviation},
 archiveprefix = {arXiv},
 arxivid = {arXiv:1011.1669v3},
 author = {Shapiro, Alexander and Dentcheva, Darinka and Ruszczy{\'{n}}ski, Andrzej},
 doi = {10.1137/1.9780898718751},
 eprint = {arXiv:1011.1669v3},
 file = {:C\:/S/Library/Shapiro, Dentcheva, Ruszczy{\'{n}}ski/2009_Lectures on Stochastic Programming.pdf:pdf;:C\:/S/Library/Shapiro, Dentcheva, Ruszczy{\'{n}}ski/2009_Lectures on Stochastic Programming(2).pdf:pdf},
 isbn = {978-0-89871-687-0},
 issn = {01676377},
 keywords = {Book,Risk Measures},
 mendeley-tags = {Book,Risk Measures},
 number = {May},
 pmid = {15776329},
 title = {{Lectures on Stochastic Programming}},
 url = {http://epubs.siam.org/doi/book/10.1137/1.9780898718751},
 year = {2009}
}

@article{Sherris2006a,
 author = {Sherris, Michael},
 file = {:C\:/S/Library/Sherris/2006_Solvency, capital allocation, and fair rate of return in insurance.pdf:pdf;:C\:/S/Library/Sherris/2006_Solvency, capital allocation, and fair rate of return in insurance(2).pdf:pdf},
 journal = {Journal of Risk and Insurance},
 keywords = {Risk Measures},
 mendeley-tags = {Risk Measures},
 number = {1},
 pages = {71--96},
 title = {{Solvency, capital allocation, and fair rate of return in insurance}},
 url = {http://onlinelibrary.wiley.com/doi/10.1111/j.1365-2966.2006.00166.x/full},
 volume = {73},
 year = {2006}
}

@article{Svindland2009,
 author = {Svindland, Gregor},
 doi = {10.1007/s11579-010-0026-x},
 file = {:C\:/S/Library/Svindland/2010_Continuity properties of law-invariant (quasi-)convex risk functions on {$Linfty$}.pdf:pdf;:C\:/S/Library/Svindland/2010_Continuity properties of law-invariant (quasi-)convex risk functions on {$Linfty$}.pdf:pdf},
 issn = {18629679},
 journal = {Mathematics and Financial Economics},
 keywords = {Duality,Fatou property,Law-invariant (quasi-)convex risk measures,Svindland},
 mendeley-tags = {Svindland},
 number = {1},
 pages = {39--43},
 title = {{Continuity properties of law-invariant (quasi-)convex risk functions on {$L^\infty$}}},
 volume = {3},
 year = {2010}
}

@article{Tasche1999,
 author = {Tasche, Dirk},
 file = {:C\:/S/Library/Tasche/1999_Risk contributions and performance measurement.pdf:pdf},
 journal = {Report of the Lehrstuhl fur mathematische Statistik, TU Munchen},
 keywords = {Risk Measures,capital asset pricing model,capm,performance measurement,portfolio selection,quan-,shortfall,tile,value at risk,var},
 mendeley-tags = {Risk Measures},
 pages = {1--26},
 title = {{Risk contributions and performance measurement}},
 url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.68.9393&rep=rep1&type=pdf},
 year = {1999}
}

@article{Tsanakas2003a,
 abstract = {The Aumann-Shapley [Values of Non-atomic Games, Princeton University Press, Princeton] value, originating in cooperative game theory, is used for the allocation of risk capital to portfolios of pooled liabilities, as proposed by Denault [Coherent allocation of risk capital, J. Risk 4 (1) (2001) 1]. We obtain an explicit formula for the Aumann-Shapley value, when the risk measure is given by a distortion premium principle [Axiomatic characterisation of insurance prices, Insur. Math. Econ. 21 (2) (1997) 173]. The capital allocated to each instrument or (sub)portfolio is given as its expected value under a change of probability measure. Motivated by Mirman and Tauman [Demand compatible equitable cost sharing prices, Math. Oper. Res. 7 (1) (1982) 40], we discuss the role of Aumann-Shapley prices in an equilibrium context and present a simple numerical example. {\textcopyright} 2003 Elsevier Science B.V. All rights reserved.},
 annote = {Very nice. Digest.},
 author = {Tsanakas, Andreas and Barnett, Christopher},
 doi = {10.1016/S0167-6687(03)00137-9},
 file = {:C\:/S/Library/Tsanakas, Barnett/2003_Risk capital allocation and cooperative pricing of insurance liabilities.pdf:pdf},
 isbn = {0167-6687, 0167-6687},
 issn = {01676687},
 journal = {Insurance: Mathematics and Economics},
 keywords = {Aumann-Shapley value,Coherent risk measures,Cooperative games,Distortion premium principle,Equilibrium,Risk Measures,Tsanakas},
 mendeley-tags = {Risk Measures,Tsanakas},
 number = {2},
 pages = {239--254},
 title = {{Risk capital allocation and cooperative pricing of insurance liabilities}},
 volume = {33},
 year = {2003}
}

@article{Venter2006,
 abstract = {Only 16 citations!},
 author = {Venter, Gary G. and Major, John A. and Kreps, Rodney E.},
 doi = {10.2143/AST.36.2.2017927},
 file = {:C\:/S/Library/Venter, Major, Kreps/2006_Marginal Decomposition of Risk Measures.pdf:pdf},
 issn = {0515-0361},
 journal = {ASTIN Bulletin},
 keywords = {GSC,Major,Risk Measures,Venter},
 mendeley-tags = {GSC,Major,Risk Measures,Venter},
 month = {oct},
 number = {2},
 pages = {375--413},
 title = {{Marginal Decomposition of Risk Measures}},
 url = {http://poj.peeters-leuven.be/content.php?url=article&id=2017927},
 volume = {36},
 year = {2006}
}

@article{Verrall2004,
 author = {Verrall, R J},
 file = {:C\:/S/Library/Verrall/2004_Bayesian Generalized Linear Model for the Bornhuetter-Furguson Method of Claims Reserving.pdf:pdf},
 journal = {North American Actuarial Journal},
 number = {3},
 pages = {67--89},
 title = {{Bayesian Generalized Linear Model for the Bornhuetter-Furguson Method of Claims Reserving}},
 volume = {8},
 year = {2004}
}

@incollection{Vitale1990,
 author = {Vitale, Richard A.},
 isbn = {978-0-940600-23-2},
 pages = {459--469},
 publisher = {Institute of Mathematical Statistics, Hayward CA},
 series = {In Topics in Statistical Dependence, Edited by H. Block, A. Sampson and T. Savits},
 title = {{On stochastic dependence and a class of degenerate distributions}},
 url = {http://projecteuclid.org/euclid.lnms/1215457581},
 year = {1990}
}

@article{Wang1995,
 abstract = {This paper proposes a new premium principle, where risk loadings are imposed by a proportional decrease in the hazard rates. This premium principle is scale invariant and additive for layers. It is shown that this principle will generate stop-loss contracts as optimal reinsurance arrangements in a competitive market when the reinsurer is less risk-averse than the direct insurer. Finally, increased limits factors are calculated based on this principle. {\textcopyright} 1995, All rights reserved.},
 author = {Wang, Shaun},
 doi = {10.1016/0167-6687(95)00010-P},
 file = {:C\:/S/Library/Wang/1995_Insurance pricing and increased limits ratemaking by proportional hazards transforms.pdf:pdf},
 issn = {01676687},
 journal = {Insurance: Mathematics and Economics},
 keywords = {Increased limits factors,Optimal reinsurance,Premium principle,Proportional hazards transform,Risk-averse,WangSS},
 mendeley-tags = {WangSS},
 number = {1},
 pages = {43--54},
 publisher = {Elsevier Science B.V.},
 title = {{Insurance pricing and increased limits ratemaking by proportional hazards transforms}},
 url = {http://dx.doi.org/10.1016/0167-6687(95)00010-P},
 volume = {17},
 year = {1995}
}

@article{Wang1996,
 abstract = {500-1000 citations},
 author = {Wang, Shaun},
 doi = {10.2143/AST.26.1.563234},
 file = {:C\:/S/Library/Wang/1996_Premium Calculation by Transforming the Layer Premium Density.pdf:pdf},
 isbn = {1783-1350},
 issn = {0515-0361},
 journal = {ASTIN Bulletin},
 keywords = {1,GSC,WangSS,comonotomcxty,i n t r,iance analysis,mean-var-,o d u c,premmm calculation principle,proportional hazard transform,stochastic dominance,t i o n},
 mendeley-tags = {GSC,WangSS},
 number = {01},
 pages = {71--92},
 title = {{Premium Calculation by Transforming the Layer Premium Density}},
 url = {https://www.cambridge.org/core/product/identifier/S0515036100003214/type/journal_article},
 volume = {26},
 year = {1996}
}

@article{WangS1998,
 abstract = {This paperpresentsa set of tools formodeling and combining correlated risks. Various correlation struc- tures are generated using copula, common mixture, com- ponent, and distortion models. These correlation struc- tures are specified in terms of (i) the joint cumulative distribution function or (ii) the joint characteristic func- tion and lend themselves to efficient methods of aggre- gation by using Monte Carlo simulation or fast Fourier transform.},
 author = {Wang, Shaun S.},
 file = {:C\:/S/Library/Wang/1998_Aggregation of correlated risk portfolios models and algorithms.pdf:pdf},
 journal = {Proceedings of the Casualty Actuarial society},
 keywords = {WangSS},
 mendeley-tags = {WangSS},
 pages = {848--939},
 title = {{Aggregation of correlated risk portfolios: models and algorithms}},
 url = {http://www.casact.com/pubs/proceed/proceed98/980848.pdf},
 year = {1998}
}

@article{Woo2002,
 abstract = {The procedure for estimating probable maximum loss (PML) for natural catastrophes has evolved over the past few decades from a rather simplistic deterministic basis to a more sophisticated methodology based on loss exceedance probability curves, generated using catastrophe modelling software. This development process is reviewed, with an emphasis on the earthquake peril, which, because of its widespread threat to critical industrial installations, has been at the forefront of most PML advances. The coherent risk definition of PML is advocated as an improvement over standard quantile methods, which can give rise to anomalous aggregation results failing to satisfy the fundamental axiom of subadditivity, and so discouraging the pooling of risks.},
 author = {Woo, G.},
 doi = {10.1017/s1357321700004037},
 file = {:C\:/S/Library/Woo/2002_Natural Catastrophe Probable Maximum Loss.pdf:pdf},
 issn = {1357-3217},
 journal = {British Actuarial Journal},
 number = {5},
 pages = {943--959},
 title = {{Natural Catastrophe Probable Maximum Loss}},
 volume = {8},
 year = {2002}
}
