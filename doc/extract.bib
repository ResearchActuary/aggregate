@article{Anderson1988,
 abstract = {In recent years catastrophe reinsurers' use of catastrophe models has been increasing until currently virtually all of the catastrophe reinsurers in the world use a catastrophe model to aid them in their pricing and portfolio management decisions. This paper explicitly models various types of reinstatement provisions, including reinstatements that are limited by the number of occurrences and by the aggregate losses; and reinstatement premiums based on the size of loss and by the time elapsed to the first occurrence. The paper also investigates the effects on the fair premium of a catastrophe treaty when various reinstatement provisions are considered. This is an expansion of the methods developed in papers by Leroy J. Simon and Bjom Sundt, which were written before the widespread use of catastrophe models. The catastrophe model used for this paper is the Insurance / Investment Risk Assessment System (IRAS) produced by Risk Management Solutions, Inc.},
 author = {Anderson, RR and Dong, Wemin},
 file = {:C\:/S/Library/Anderson, Dong/1988_Pricing catastrophe reinsurance with reinstatement provisions using a catastrophe model.pdf:pdf},
 journal = {Casualty Actuarial Society Forum},
 pages = {303--322},
 title = {{Pricing catastrophe reinsurance with reinstatement provisions using a catastrophe model}},
 url = {http://casact.net/education/ratesem/99handouts/anderson.pdf},
 year = {1988}
}

@book{AonBenfield2015f,
 author = {{Aon Benfield}},
 edition = {10},
 file = {:C\:/S/Library/Aon Benfield/2015_Insurance Risk Study, Ed. 10.pdf:pdf},
 keywords = {Aon,Insurance Risk Study},
 mendeley-tags = {Aon,Insurance Risk Study},
 title = {{Insurance Risk Study, Ed. 10}},
 year = {2015}
}

@article{Bear1990,
 author = {Bear, R.A. and Nemlick, K.J.},
 doi = {10.1016/0167-6687(93)91078-9},
 file = {:C\:/S/Library/Bear, Nemlick/1990_Pricing the impact of adjustable features and loss sharing provisions of reinsurance treaties.pdf:pdf},
 issn = {01676687},
 journal = {Proceedings of the Casualty Actuarial Society},
 number = {147},
 pages = {86--87},
 title = {{Pricing the impact of adjustable features and loss sharing provisions of reinsurance treaties}},
 volume = {77},
 year = {1990}
}

@article{Bernegger1997,
 author = {Bernegger, Stefan},
 file = {:C\:/S/Library/Bernegger/1997_The Swiss Re exposure curves and the MBBEFD distribution class.pdf:pdf},
 journal = {ASTIN Bulletin},
 number = {1},
 pages = {99--111},
 title = {{The Swiss Re exposure curves and the MBBEFD distribution class}},
 volume = {27},
 year = {1997}
}

@article{Boonen2017,
 abstract = {Existing risk capital allocation methods, such as the Euler rule, work under the explicit assumption that portfolios are formed as linear combinations of random loss/profit variables, with the firm being able to choose the portfolio weights. This assumption is unrealistic in an insurance context, where arbitrary scaling of risks is generally not possible. Here, we model risks as being partially generated by L{\'{e}}vy processes, capturing the non-linear aggregation of risk. The model leads to non-homogeneous fuzzy games, for which the Euler rule is not applicable. For such games, we seek capital allocations that are in the core, that is, do not provide incentives for splitting portfolios. We show that the Euler rule of an auxiliary linearised fuzzy game (non-uniquely) satisfies the core property and, thus, provides a plausible and easily implemented capital allocation. In contrast, the Aumann–Shapley allocation does not generally belong to the core. For the non-homogeneous fuzzy games studied, Tasche's (1999) criterion of suitability for performance measurement is adapted and it is shown that the proposed allocation method gives appropriate signals for improving the portfolio underwriting profit.},
 author = {Boonen, Tim J. and Tsanakas, Andreas and W{\"{u}}thrich, Mario V.},
 doi = {10.1016/j.insmatheco.2016.11.003},
 file = {:C\:/S/Library/Boonen, Tsanakas, W{\"{u}}thrich/2017_Capital allocation for portfolios with non-linear risk aggregation(2).pdf:pdf},
 issn = {01676687},
 journal = {Insurance: Mathematics and Economics},
 keywords = {Aumann–Shapley value,Capital allocation,Euler rule,Fuzzy core,Risk measures,Tsanakas},
 mendeley-tags = {Tsanakas},
 pages = {95--106},
 title = {{Capital allocation for portfolios with non-linear risk aggregation}},
 volume = {72},
 year = {2017}
}

@article{Brown1983,
 abstract = {The asymptotic formula for the variance of a percentile estimate is inversely proportional to the square of the probability density function evaluated at that percentile. In this note we show, for small and moderate sample sizes, that the estimate of the variance can have a moderate to large coefficient of variation even when the form of the density is known. When the density must be estimated empirically, the coefficient of variation increases substantially. We conclude that the estimate of the variance should not be used in either confidence interval estimation or hypothesis testing except for very large sample sizes. {\textcopyright} 1983.},
 author = {Brown, Morton B. and Wolfe, Robert A.},
 doi = {10.1016/0167-9473(83)90088-9},
 file = {:C\:/S/Library/Brown, Wolfe/1983_Estimation of the variance of percentile estimates.pdf:pdf},
 issn = {01679473},
 journal = {Computational Statistics and Data Analysis},
 keywords = {Estimation,Percentile estimates},
 number = {C},
 pages = {167--174},
 title = {{Estimation of the variance of percentile estimates}},
 volume = {1},
 year = {1983}
}

@article{Clark2014,
 author = {Clark, David R},
 file = {:C\:/S/Library/Clark/2014_Basics of Reinsurance Pricing Actuarial Study Note.pdf:pdf},
 journal = {CAS Study Note},
 title = {{Basics of Reinsurance Pricing Actuarial Study Note}},
 url = {http://www.casact.org/library/studynotes/Clark_2014.pdf},
 year = {2014}
}

@book{Conover1999,
 author = {Conover, W J},
 edition = {Third},
 publisher = {John Wiley and Sons},
 title = {{Practical nonparametric statistics}},
 year = {1999}
}

@article{Consul1973,
 abstract = {A new generalization of the Poisson distribution, with two parameters $\lambda$1 and $\lambda$2 is obtained as a limiting form of the generalized negative binomial distribution. The variance of the distribution is greater than, equal to or smaller than the mean according as $\lambda$2 is positive, zero or negative. The distribution gives a very close fit to supposedly binomial, Poisson and negative-binomial data and provides with a model suitable to most unimodel or reverse J-shaped distributions. Diagrams showing the variations in the form of the distribution for different values of $\lambda$1 and $\lambda$2 are given.},
 author = {Consul, P C and Jain, G C},
 doi = {10.1080/00401706.1973.10489112},
 file = {:C\:/S/Library/Consul, Jain/1973_A generalization of the poisson distribution(2).pdf:pdf},
 issn = {15372723},
 journal = {Technometrics},
 keywords = {Fits binomial and negative binomial data,Poisson distribution generalization,Queueing model,Two-parameter versatile model},
 number = {4},
 pages = {791--799},
 title = {{A generalization of the poisson distribution}},
 url = {https://www.jstor.org/stable/pdf/1267389.pdf},
 volume = {15},
 year = {1973}
}

@article{Denuit2019,
 abstract = {Using risk-reducing properties of conditional expectations with respect to convex order, Denuit and Dhaene [Denuit, M. and Dhaene, J. (2012). Insurance: Mathematics and Economics 51, 265-270] proposed the conditional mean risk sharing rule to allocate the total risk among participants to an insurance pool. This paper relates the conditional mean risk sharing rule to the size-biased transform when pooled risks are independent. A representation formula is first derived for the conditional expectation of an individual risk given the aggregate loss. This formula is then exploited to obtain explicit expressions for the contributions to the pool when losses are modeled by compound Poisson sums, compound Negative Binomial sums, and compound Binomial sums, to which Panjer recursion applies. Simple formulas are obtained when claim severities are homogeneous. A couple of applications are considered: first, to a peer-to-peer insurance scheme where participants share the first layer of their respective risks while the higher layer is ceded to a (re)insurer; second, to survivor credits to be shared among surviving participants in tontine schemes.},
 author = {Denuit, Michel},
 doi = {10.1017/asb.2019.24},
 file = {:C\:/S/Library/Denuit/2019_Size-biased transform and conditional mean risk sharing, with application to p2p insurance and tontines.pdf:pdf},
 issn = {17831350},
 journal = {ASTIN Bulletin},
 keywords = {Conditional expectation,Panjer family of distributions,compound distributions,risk measures,risk pooling},
 number = {3},
 pages = {591--617},
 title = {{Size-biased transform and conditional mean risk sharing, with application to p2p insurance and tontines}},
 volume = {49},
 year = {2019}
}

@article{Denuit2022b,
 abstract = {Survivor funds are financial arrangements where participants agree to share the proceeds of a collective investment pool in a predescribed way depending on their survival. This offers investors a way to benefit from mortality credits, boosting financial returns. Following Denuit (2019, ASTIN Bulletin, 49, 591-617), participants are assumed to adopt the conditional mean risk sharing rule introduced in Denuit and Dhaene (2012, Insurance: Mathematics and Economics, 51, 265-270) to assess their respective shares in mortality credits. This paper looks at pools of individuals that are heterogeneous in terms of their survival probability and their contributions. Imposing mild conditions, we show that individual risk can be fully diversified if the size of the group tends to infinity. For large groups, we derive simple, hierarchical approximations of the conditional mean risk sharing rule.},
 author = {Denuit, Michel and Hieber, Peter and Robert, Christian Y.},
 doi = {10.1017/asb.2022.13},
 file = {:C\:/S/Library/Denuit, Hieber, Robert/2022_Mortality Credits Within Large Survivor Funds.pdf:pdf},
 issn = {17831350},
 journal = {ASTIN Bulletin},
 keywords = {Mortality risk pooling,conditional mean risk sharing,tontine},
 number = {3},
 pages = {813--834},
 title = {{Mortality Credits Within Large Survivor Funds}},
 volume = {52},
 year = {2022}
}

@article{Embrechts2009a,
 abstract = {Numerical evaluation of compound distributions is an important task in insurance mathematics and quantitative risk management. In practice, both recursive methods as well as transform based techniques are widely used. We give a survey of these tools, point out the respective merits and provide some numerical examples. {\textcopyright} 2008 Springer-Verlag.},
 author = {Embrechts, Paul and Frei, Marco},
 doi = {10.1007/s00186-008-0249-2},
 file = {:C\:/S/Library/Embrechts, Frei/2009_Panjer recursion versus FFT for compound distributions.pdf:pdf},
 issn = {14322994},
 journal = {Mathematical Methods of Operations Research},
 keywords = {Compound distributions,Fast Fourier transform,Panjer recursion,Risk management},
 number = {3},
 pages = {497--508},
 title = {{Panjer recursion versus FFT for compound distributions}},
 volume = {69},
 year = {2009}
}

@article{Embrechts2013,
 abstract = {Despite well-known shortcomings as a risk measure, Value-at-Risk (VaR) is still the industry and regulatory standard for the calculation of risk capital in banking and insurance. This paper is concerned with the numerical estimation of the VaR for a portfolio position as a function of different dependence scenarios on the factors of the portfolio. Besides summarizing the most relevant analytical bounds, including a discussion of their sharpness, we introduce a numerical algorithm which allows for the computation of reliable (sharp) bounds for the VaR of high-dimensional portfolios with dimensions d possibly in the several hundreds. We show that additional positive dependence information will typically not improve the upper bound substantially. In contrast higher order marginal information on the model, when available, may lead to strongly improved bounds. Several examples of practical relevance show how explicit VaR bounds can be obtained. These bounds can be interpreted as a measure of model uncertainty induced by possible dependence scenarios. ?? 2013 Elsevier B.V.},
 author = {Embrechts, Paul and Puccetti, Giovanni and Ruschendorf, Ludger},
 doi = {10.1016/j.jbankfin.2013.03.014},
 file = {:C\:/S/Library/Embrechts, Puccetti, Ruschendorf/2013_Model uncertainty and VaR aggregation.pdf:pdf},
 isbn = {3905543745},
 issn = {03784266},
 journal = {Journal of Banking and Finance},
 keywords = {Copula,Fr??chet class,Model uncertainity,Operational Risk,Positive dependence,Rearrangement algorithm,Risk Measures,Risk aggregation,Tails},
 mendeley-tags = {Risk Measures,Tails},
 number = {8},
 pages = {2750--2764},
 title = {{Model uncertainty and VaR aggregation}},
 volume = {37},
 year = {2013}
}

@book{feller71,
 abstract = {The exponential and the uniform densities; Special densities. Randomization; Densities in higher dimensions. Normal densities and processes; Probability measures and spaces; Probability distributions in Rr; A survey of some important distributions and processes; Laws of large numbers. Aplications in analysis; The basic limit theorems; Infinitely divisible distributions and semi-groups; Markov processes and semi-groups; Renewal theory; Random walks in R1; Laplace transforms. Tauberian theorems. Resolvents; Aplications of Laplace transforms; Characteristic functions; Expansions related to the central limit theorem; Infinitely divisible distributions; Applications of Fourier methods to ramdom walks; harmonic analysis; Answers to problems.},
 author = {Feller, William},
 edition = {Second},
 isbn = {0471257095},
 pages = {669},
 publisher = {J. Wiley and Sons},
 title = {{An Introduction to Probability Theory and its Applications, Volume 2}},
 year = {1971}
}

@article{Grubel1999,
 author = {Grubel, Rudolf and Hermesmeier, Renate},
 doi = {10.2143/AST.29.2.504611},
 file = {:C\:/S/Library/Grubel, Hermesmeier/1999_Computation of Compound Distributions I Aliasing Errors and Exponential Tilting(2).pdf:pdf},
 issn = {17831350},
 journal = {Astin Bulletin},
 keywords = {aliasing,and phrases,change of measure,fourier,random sums,ruin probabilities,total claim size distribution,transformation},
 number = {2},
 pages = {197--214},
 title = {{Computation of Compound Distributions I: Aliasing Errors and Exponential Tilting}},
 volume = {29},
 year = {1999}
}

@article{Heckman1983,
 abstract = {This paper discusses aggregate loss distributions from the perspective of collective risk theory. An accurate, efficient and practical algorithm is given for calculating cumulative probabilities and excess pure premiums. The input re-quired is the claim severity and claim count distributions. One of the main drawbacks of the collective risk model is the uncertainty of the parameters of the claim severity and claim count distributions. Modifi-cations of the collective risk model are proposed to deal with these problems. These modifications are incorporated into the algorithm. Examples are given illustrating the use of this algorithm. They include (1) calculating the pure premium for a policy with an aggregate limit; (2) calculating the pure premium of an aggregate stop-loss policy for group life insurance; and (3) calculating the insurance charge for a multi-line retrospective rating plan, including a line which is itself subject to an aggregate limit.},
 author = {Heckman, Philip E and Meyers, Glenn G},
 file = {:C\:/S/Library/Heckman, Meyers/1983_The calculation of aggregate loss distributions from claim severity and claim count distributions.pdf:pdf},
 journal = {Proceedings of the Casualty Actuarial Society},
 keywords = {Meyers},
 mendeley-tags = {Meyers},
 pages = {49--66},
 title = {{The calculation of aggregate loss distributions from claim severity and claim count distributions}},
 year = {1983}
}

@article{Hyndman1996,
 abstract = {There are a large number of different definitions used for sample quantiles in statistical computer packages. Often within the same package one definition will be used to compute a quantile explicitly, while other definitions may be used when producing a boxplot, a probability plot, or a QQ plot. We compare the most commonly implemented sample quantile definitions by writing them in a common notation and investigating their motivation and some of their properties. We argue that there is a need to adopt a standard definition for sample quantiles so that the same answers are produced by different packages and within each package. We conclude by recommending that the median-unbiased estimator be used because it has most of the desirable properties of a quantile estimator and can be defined independently of the underlying distribution. {\textcopyright} 1996 Taylor & Francis Group, LLC.},
 author = {Hyndman, Rob J. and Fan, Yanan},
 doi = {10.1080/00031305.1996.10473566},
 file = {:C\:/S/Library/Hyndman, Fan/1996_Sample Quantiles in Statistical Packages.pdf:pdf},
 issn = {15372731},
 journal = {American Statistician},
 keywords = {Percentiles,Quartiles,Sample quantiles,Statistical computer packages},
 number = {4},
 pages = {361--365},
 title = {{Sample Quantiles in Statistical Packages}},
 volume = {50},
 year = {1996}
}

@unpublished{Jewson2022b,
 author = {Jewson, Stephen},
 file = {:C\:/S/Library/Jewson/2022_Projections of Changes in U.S. Hurricane Damage Due to Projected Changes in Hurricane Frequencies.pdf:pdf},
 title = {{Projections of Changes in U.S. Hurricane Damage Due to Projected Changes in Hurricane Frequencies}},
 year = {2022}
}

@book{Jorgensen1997,
 author = {J{\o}rgensen, Bent},
 file = {:C\:/S/Library/J{\o}rgensen/1997_The theory of dispersion models(2).pdf:pdf},
 publisher = {CRC Press},
 title = {{The theory of dispersion models}},
 year = {1997}
}

@article{Ludwig1991,
 author = {Ludwig, B Y Stephen J},
 file = {:C\:/S/Library/Ludwig/1991_AN EXPOSURE RATING APPROACH TO PRICING(2).pdf:pdf},
 journal = {Proceedings of the Casualty Actuarial Society},
 title = {{AN EXPOSURE RATING APPROACH TO PRICING}},
 year = {1991}
}

@inproceedings{Mata2002,
 author = {Mata, Ana J and Ph, D and Fannin, Brian and Verheyen, Mark A},
 booktitle = {General Insurance Convention},
 file = {:C\:/S/Library/Mata et al/2002_Pricing Excess of Loss Treaty with Loss Sensitive Features An Exposure Rating Approach.pdf:pdf},
 title = {{Pricing Excess of Loss Treaty with Loss Sensitive Features: An Exposure Rating Approach}},
 year = {2002}
}

@article{Meyers2019,
 author = {Meyers, Glenn G},
 file = {:C\:/S/Library/Meyers/2019_A Cost of Capital Risk Margin Formula For Non-Life Insurance Liabilities.pdf:pdf},
 journal = {Variance},
 keywords = {Meyers,bayesian mcmc,capital requirements,risk margins,stochastic loss reserving},
 mendeley-tags = {Meyers},
 number = {2},
 pages = {186--198},
 title = {{A Cost of Capital Risk Margin Formula For Non-Life Insurance Liabilities}},
 volume = {12},
 year = {2019}
}

@article{Mildenhall2004,
 author = {Mildenhall, Stephen J},
 file = {:C\:/S/Library/Mildenhall/2004_A Note on the Myers and Read Capital Allocation Formula.pdf:pdf},
 issn = {10920277},
 journal = {North American Actuarial Journal},
 keywords = {capital and ownership structure,financing policy,g - financial economics,g220 - insurance,g320 -,insurance companies},
 number = {2},
 pages = {32--44},
 title = {{A Note on the Myers and Read Capital Allocation Formula}},
 url = {http://library.soa.org/library-pdf/naaj0402_3.pdf},
 volume = {8},
 year = {2004}
}

@article{Mildenhall2005a,
 author = {Mildenhall, Stephen J},
 file = {:C\:/S/Library/Mildenhall/2005_Correlation and Aggregate Loss Distributions With An Emphasis On The Iman-Conover Method.pdf:pdf},
 journal = {Casualty Actuarial Society Forum},
 title = {{Correlation and Aggregate Loss Distributions With An Emphasis On The Iman-Conover Method}},
 volume = {Winter},
 year = {2005}
}

@article{Mildenhall2017b,
 annote = {Quick summary for Risks cover. 

Actuarial Geometry studies how the shape of an aggregate loss distribution changes as expected loss volume changes. The theory of Markov processes implies Levy processes are straight lines even though their distribution changes shape as expected losses increase. In contrast, an asset-return model retains a constant shape but represents a curved path. The difference is significant in the theory of risk measures and capital allocation, which are based on marginal changes in loss volume. In the figure the Levy process (red) is a great circle straight line whereas the asset model (blue) is a curved path. Growth along the two paths results in different measures of marginal risk (top right).},
 author = {Mildenhall, Stephen J},
 doi = {10.3390/risks5020031},
 file = {:C\:/S/Library/Mildenhall/2017_Actuarial Geometry.pdf:pdf},
 issn = {2227-9091},
 journal = {Risks},
 keywords = {capital allocation,capital determination,game,risk measure},
 number = {31},
 title = {{Actuarial Geometry}},
 volume = {5},
 year = {2017}
}

@book{Mildenhall2022a,
 author = {Mildenhall, Stephen J. and Major, John A.},
 file = {:C\:/S/Library/Mildenhall, Major/2022_Pricing Insurance Risk Theory and Practice.pdf:pdf},
 isbn = {9781119130536},
 publisher = {John Wiley & Sons, Inc.},
 title = {{Pricing Insurance Risk: Theory and Practice}},
 year = {2022}
}

@book{MitchellWallace2017,
 author = {Mitchell-Wallace, Kirsten and Jones, Matthew and Hillier, John and Foote, Matthew},
 chapter = {Chapter 1},
 file = {:C\:/S/Library/Mitchell-Wallace et al/2017_Natural Catastrophe Risk Managment and Modeling - A Practitioner's Guide.pdf:pdf},
 publisher = {Wiley-Blackwell},
 title = {{Natural Catastrophe Risk Managment and Modeling - A Practitioner's Guide}},
 year = {2017}
}

@book{Parodi2015,
 author = {Parodi, Pietro},
 file = {:C\:/S/Library/Parodi/2015_Pricing in General Insurance.pdf:pdf},
 isbn = {9781466581487},
 keywords = {Book},
 mendeley-tags = {Book},
 publisher = {CRC Press},
 title = {{Pricing in General Insurance}},
 url = {file:///C:/Users/youhe/Downloads/kdoc_o_00042_01.pdf},
 year = {2015}
}

@article{Puccetti2012,
 abstract = {We propose a new algorithm to compute numerically sharp lower and upper bounds on the distribution of a function of d dependent random variables having fixed marginal distributions. Compared to the existing literature, the bounds are widely applicable, more accurate and more easily obtained. ?? 2011 Elsevier B.V. All rights reserved.},
 author = {Puccetti, Giovanni and Ruschendorf, Ludger},
 doi = {10.1016/j.cam.2011.10.015},
 file = {:C\:/S/Library/Puccetti, Ruschendorf/2012_Computation of sharp bounds on the distribution of a function of dependent risks.pdf:pdf},
 issn = {03770427},
 journal = {Journal of Computational and Applied Mathematics},
 keywords = {Bounds for dependent risks,Distribution functions,Rearrangements,Risk Measures,Tails},
 mendeley-tags = {Risk Measures,Tails},
 number = {7},
 pages = {1833--1840},
 publisher = {Elsevier B.V.},
 title = {{Computation of sharp bounds on the distribution of a function of dependent risks}},
 url = {http://dx.doi.org/10.1016/j.cam.2011.10.015},
 volume = {236},
 year = {2012}
}

@article{Robertson1992,
 author = {Robertson, John P.},
 file = {:C\:/S/Library/Robertson/1992_The computation of aggregate loss distributions.pdf:pdf},
 journal = {Proceedings of the Casualty Actuarial Society},
 number = {150},
 pages = {57--133},
 title = {{The computation of aggregate loss distributions}},
 volume = {79},
 year = {1992}
}

@book{Strain1997,
 author = {Strain, Robert W.},
 publisher = {Robert W. Strain Publishing & Seminars, Incorporated},
 title = {{Reinsurance}},
 year = {1997}
}

@article{Wang1995,
 abstract = {This paper proposes a new premium principle, where risk loadings are imposed by a proportional decrease in the hazard rates. This premium principle is scale invariant and additive for layers. It is shown that this principle will generate stop-loss contracts as optimal reinsurance arrangements in a competitive market when the reinsurer is less risk-averse than the direct insurer. Finally, increased limits factors are calculated based on this principle. {\textcopyright} 1995, All rights reserved.},
 author = {Wang, Shaun},
 doi = {10.1016/0167-6687(95)00010-P},
 file = {:C\:/S/Library/Wang/1995_Insurance pricing and increased limits ratemaking by proportional hazards transforms.pdf:pdf},
 issn = {01676687},
 journal = {Insurance: Mathematics and Economics},
 keywords = {Increased limits factors,Optimal reinsurance,Premium principle,Proportional hazards transform,Risk-averse,WangSS},
 mendeley-tags = {WangSS},
 number = {1},
 pages = {43--54},
 publisher = {Elsevier Science B.V.},
 title = {{Insurance pricing and increased limits ratemaking by proportional hazards transforms}},
 url = {http://dx.doi.org/10.1016/0167-6687(95)00010-P},
 volume = {17},
 year = {1995}
}

@article{Wang1996,
 abstract = {500-1000 citations},
 author = {Wang, Shaun},
 doi = {10.2143/AST.26.1.563234},
 file = {:C\:/S/Library/Wang/1996_Premium Calculation by Transforming the Layer Premium Density.pdf:pdf},
 isbn = {1783-1350},
 issn = {0515-0361},
 journal = {ASTIN Bulletin},
 keywords = {1,GSC,WangSS,comonotomcxty,i n t r,iance analysis,mean-var-,o d u c,premmm calculation principle,proportional hazard transform,stochastic dominance,t i o n},
 mendeley-tags = {GSC,WangSS},
 number = {01},
 pages = {71--92},
 title = {{Premium Calculation by Transforming the Layer Premium Density}},
 url = {https://www.cambridge.org/core/product/identifier/S0515036100003214/type/journal_article},
 volume = {26},
 year = {1996}
}

@article{WangS1998,
 abstract = {This paperpresentsa set of tools formodeling and combining correlated risks. Various correlation struc- tures are generated using copula, common mixture, com- ponent, and distortion models. These correlation struc- tures are specified in terms of (i) the joint cumulative distribution function or (ii) the joint characteristic func- tion and lend themselves to efficient methods of aggre- gation by using Monte Carlo simulation or fast Fourier transform.},
 author = {Wang, S},
 file = {:C\:/S/Library/Wang/1998_Aggregation of correlated risk portfolios models and algorithms.pdf:pdf},
 journal = {Proceedings of the Casualty Actuarial society},
 keywords = {WangSS},
 mendeley-tags = {WangSS},
 pages = {848--939},
 title = {{Aggregation of correlated risk portfolios: models and algorithms}},
 url = {http://www.casact.com/pubs/proceed/proceed98/980848.pdf},
 year = {1998}
}

@article{Woo2002,
 abstract = {The procedure for estimating probable maximum loss (PML) for natural catastrophes has evolved over the past few decades from a rather simplistic deterministic basis to a more sophisticated methodology based on loss exceedance probability curves, generated using catastrophe modelling software. This development process is reviewed, with an emphasis on the earthquake peril, which, because of its widespread threat to critical industrial installations, has been at the forefront of most PML advances. The coherent risk definition of PML is advocated as an improvement over standard quantile methods, which can give rise to anomalous aggregation results failing to satisfy the fundamental axiom of subadditivity, and so discouraging the pooling of risks.},
 author = {Woo, G.},
 doi = {10.1017/s1357321700004037},
 file = {:C\:/S/Library/Woo/2002_Natural Catastrophe Probable Maximum Loss.pdf:pdf},
 issn = {1357-3217},
 journal = {British Actuarial Journal},
 number = {5},
 pages = {943--959},
 title = {{Natural Catastrophe Probable Maximum Loss}},
 volume = {8},
 year = {2002}
}
